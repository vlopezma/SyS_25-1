{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlopezma/SyS_25-1/blob/main/Dashboard_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "u5S2b1wHBAYt"
      },
      "outputs": [],
      "source": [
        "#instalaci√≥n de librer√≠as\n",
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instalar librerias necesarias para descargar audios youtube\n",
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
        "!pip install soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfRfedy8QRGm",
        "outputId": "4f6dc4fe-b1ac-4204-f586-60a98b04205c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
            "  Using cached https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz (2.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: yt-dlp\n",
            "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yt-dlp: filename=yt_dlp-2025.5.22-py3-none-any.whl size=3012622 sha256=3d924af3359fa0fa07fa033defdbf45d1207e23ce0dac35978c5b9eac4fd88f3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wu6aehmu/wheels/2d/79/97/7209650ef73114e0fe0603480da012ad3afacb9cae6b8acd9a\n",
            "Successfully built yt-dlp\n",
            "Installing collected packages: yt-dlp\n",
            "  Attempting uninstall: yt-dlp\n",
            "    Found existing installation: yt-dlp 2025.5.22\n",
            "    Uninstalling yt-dlp-2025.5.22:\n",
            "      Successfully uninstalled yt-dlp-2025.5.22\n",
            "Successfully installed yt-dlp-2025.5.22\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pages"
      ],
      "metadata": {
        "id": "7a4Sn6_0BTUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904b08a0-af04-41de-8642-4c28bcf98ec3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‚Äòpages‚Äô: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 0_Detector.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Detector üéµ\",\n",
        "    page_icon=\"üéº\",\n",
        ")\n",
        "\n",
        "st.write(\"# Bienvenido al detector de g√©neros musicales. üéµüé∂üéº\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    En este dashboard de Streamlit podr√°s analizar un link de youtube para detectar si pertenece al g√©nero **rock** o **pop**.\n",
        "\n",
        "    Utilizaremos la **Transformada R√°pida de Fourier (FFT)** para analizar el contenido en frecuencias de la m√∫sica, lo que nos permitir√° identificar caracter√≠sticas propias de cada g√©nero.\n",
        "\"\"\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV_NUgcjBWO6",
        "outputId": "6608f828-327d-4c09-d332-4495a7a8febe"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 0_Detector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 1_Detector_FFT.py\n",
        "\n",
        "import streamlit as st\n",
        "import time\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import os\n",
        "import yt_dlp as youtube_dl\n",
        "import browser_cookie3\n",
        "import joblib\n",
        "import soundfile as sf\n",
        "from scipy.signal import resample_poly\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from umap import UMAP\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "st.set_page_config(page_title=\"An√°lisis FFT del audio\", page_icon=\"üìä\")\n",
        "\n",
        "st.markdown(\"# An√°lisis de Frecuencias (FFT)\")\n",
        "st.sidebar.header(\"Detector de G√©nero Musical\")\n",
        "st.write(\"En esta secci√≥n se analizar√° la se√±al de audio usando la Transformada R√°pida de Fourier (FFT) para detectar si la canci√≥n es Rock o Reggaet√≥n.\")\n",
        "\n",
        "# Espacio para pegar un enlace de YouTube o cargar archivo\n",
        "st.subheader(\"üîó Ingresa el enlace de la canci√≥n (YouTube) o carga un archivo de audio:\")\n",
        "link = st.text_input(\"Enlace de YouTube\", \"\")\n",
        "uploaded_file = st.file_uploader(\"...o sube un archivo de audio (.wav)\", type=[\"wav\"])\n",
        "\n",
        "try:\n",
        "    cookies = browser_cookie3.firefox()\n",
        "except:\n",
        "    print(\"No se pueden descargar cookies desde firefox. Intentando Chrome...\")\n",
        "    try:\n",
        "        cookies = browser_cookie3.chrome()\n",
        "    except:\n",
        "        print(\"No se pueden descargar cookies desde Chrome. Por favor aseg√∫rate de estar logueado en Youtube desde tu navegador.\")\n",
        "        cookies = None\n",
        "\n",
        "# Paso 3: Adaptar Audio Processing\n",
        "@st.cache_resource # Cache the model loading\n",
        "def load_model(filename=\"modelo/rock_vs_pop.pkl\"):\n",
        "    try:\n",
        "        model_data = joblib.load(filename)\n",
        "        return model_data\n",
        "    except FileNotFoundError:\n",
        "        st.error(f\"Error: El archivo del modelo '{filename}' no fue encontrado.\")\n",
        "        st.info(\"Por favor, aseg√∫rate de que el archivo del modelo est√© en la ubicaci√≥n correcta.\")\n",
        "        return None\n",
        "\n",
        "model_data = load_model()\n",
        "\n",
        "if model_data:\n",
        "    loaded_model = model_data['modelo']\n",
        "    vf = model_data['vf']\n",
        "    fs = model_data['fs']\n",
        "    type_labels = model_data['type']\n",
        "    # You might also want to load the scaler used for normalizing the FFT data\n",
        "    # Assuming it was saved in the model_data dictionary\n",
        "    # sca = model_data['scaler'] # Uncomment if you saved the scaler\n",
        "\n",
        "\n",
        "    def download_ytvid_as_mp3(video_url, name):\n",
        "        options = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'keepvideo': False,\n",
        "            'outtmpl': f'{name}.mp3',\n",
        "        }\n",
        "        try:\n",
        "            # Attempt to get cookies from the browser (might not work in all deployment environments)\n",
        "            cookies = browser_cookie3.chrome() # Or firefox()\n",
        "            options['cookiejar'] = cookies\n",
        "        except:\n",
        "            st.warning(\"No se pudieron obtener cookies del navegador. La descarga podr√≠a fallar para algunos videos.\")\n",
        "            cookies = None # Ensure cookies is None if retrieval fails\n",
        "\n",
        "\n",
        "        with youtube_dl.YoutubeDL(options) as ydl:\n",
        "            try:\n",
        "                video_info = ydl.extract_info(video_url, download=False)\n",
        "                ydl.download([video_info['webpage_url']])\n",
        "                st.success(f\"Descarga completa: {name}.mp3\")\n",
        "                return f\"{name}.mp3\"\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error descargando {video_url}: {e}\")\n",
        "                return None\n",
        "\n",
        "    def process_audio(audio_path, target_fs=48000, segment_ts=5, tl=[30,40,50,60,70,80]):\n",
        "        try:\n",
        "            x, fs_i = sf.read(audio_path)\n",
        "\n",
        "            if x.ndim == 1:\n",
        "                x = np.expand_dims(x, axis=1)\n",
        "            if x.shape[1] == 1:\n",
        "                x = np.repeat(x, 2, axis=1)\n",
        "\n",
        "            segments = []\n",
        "            # The target number of samples for each segment at the target fs\n",
        "            segment_length_fs = int(segment_ts * target_fs)\n",
        "\n",
        "            for ti in tl:\n",
        "                start_sample = int(fs_i * ti)\n",
        "                end_sample = int(fs_i * (ti + segment_ts))\n",
        "\n",
        "                if end_sample > len(x):\n",
        "                    st.warning(f\"Saltando segmento de {ti}s a {ti+segment_ts}s: fuera de rango del archivo.\")\n",
        "                    continue\n",
        "\n",
        "                xc = x[start_sample:end_sample, :]\n",
        "\n",
        "                if fs_i != target_fs:\n",
        "                    try:\n",
        "                        # Resample using resample_poly\n",
        "                        gcd_val = np.gcd(target_fs, fs_i)\n",
        "                        up_val = target_fs // gcd_val\n",
        "                        down_val = fs_i // gcd_val\n",
        "\n",
        "                        xc_resampled_ch1 = resample_poly(xc[:, 0], up=up_val, down=down_val)\n",
        "                        xc_resampled_ch2 = resample_poly(xc[:, 1], up=up_val, down=down_val)\n",
        "\n",
        "                        xc_resampled = np.stack((xc_resampled_ch1, xc_resampled_ch2), axis=-1)\n",
        "\n",
        "                        # Ensure the resampled segment has the target length\n",
        "                        if xc_resampled.shape[0] > segment_length_fs:\n",
        "                            xc_resampled = xc_resampled[:segment_length_fs, :]\n",
        "                        elif xc_resampled.shape[0] < segment_length_fs:\n",
        "                            padding = np.zeros((segment_length_fs - xc_resampled.shape[0], 2))\n",
        "                            xc_resampled = np.vstack((xc_resampled, padding))\n",
        "\n",
        "                        xc = xc_resampled\n",
        "                        st.info(f\"Segmento de {ti}s a {ti+segment_ts}s: Remuestreado a {target_fs} Hz.\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Error remuestreando segmento de {ti}s a {ti+segment_ts}s: {e}\")\n",
        "                        continue # Skip this segment on resampling error\n",
        "\n",
        "\n",
        "                if xc.shape[0] == segment_length_fs:\n",
        "                     segments.append(xc)\n",
        "                else:\n",
        "                     st.warning(f\"Segmento de {ti}s a {ti+segment_ts}s tiene longitud incorrecta despu√©s de procesar: {xc.shape[0]}. Esperado: {segment_length_fs}. Saltando.\")\n",
        "\n",
        "\n",
        "            if not segments:\n",
        "                 st.error(\"No se pudieron extraer segmentos v√°lidos del audio.\")\n",
        "                 return None\n",
        "\n",
        "            return np.array(segments)\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error procesando archivo de audio {audio_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    if st.button(\"Analizar\"):\n",
        "        audio_path = None\n",
        "        if link:\n",
        "            with st.spinner(\"Descargando audio de YouTube...\"):\n",
        "                mp3_file = download_ytvid_as_mp3(link, \"downloaded_audio\")\n",
        "                if mp3_file:\n",
        "                    wav_file = \"downloaded_audio.wav\"\n",
        "                    with st.spinner(\"Convirtiendo a WAV...\"):\n",
        "                        try:\n",
        "                            subprocess.call(['ffmpeg', '-y', '-i', mp3_file, wav_file])\n",
        "                            audio_path = wav_file\n",
        "                            st.success(\"Conversi√≥n a WAV completa.\")\n",
        "                        except Exception as e:\n",
        "                            st.error(f\"Error convirtiendo a WAV: {e}\")\n",
        "                            audio_path = None\n",
        "                    os.remove(mp3_file) # Clean up mp3 file\n",
        "        elif uploaded_file:\n",
        "            # Save the uploaded file temporarily\n",
        "            with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "                f.write(uploaded_file.getbuffer())\n",
        "            audio_path = \"uploaded_audio.wav\"\n",
        "            st.success(\"Archivo WAV cargado.\")\n",
        "\n",
        "        if audio_path:\n",
        "            with st.spinner(\"Procesando audio y extrayendo caracter√≠sticas...\"):\n",
        "                audio_segments = process_audio(audio_path, fs)\n",
        "\n",
        "                if audio_segments is not None:\n",
        "                    # Calcular la transformada de Fourier y normalizar\n",
        "                    Xw = np.fft.rfft(audio_segments, axis=1).mean(axis=-1) # Already handled stereo in process_audio\n",
        "                    # Ensure sca is loaded or re-fit if needed. For simplicity, refitting here.\n",
        "                    # If you saved and loaded the scaler, use the loaded one.\n",
        "                    sca = MinMaxScaler()\n",
        "                    # You might want to fit the scaler on your training data's FFT results first\n",
        "                    # and then use that fitted scaler here for consistent normalization.\n",
        "                    # For now, fitting on the current audio segments' FFT is done for demonstration.\n",
        "                    Xw_normalized = sca.fit_transform(np.abs(Xw))\n",
        "\n",
        "\n",
        "                    # Paso 4: Integrar Machine Learning Model y predecir\n",
        "                    with st.spinner(\"Realizando predicci√≥n...\"):\n",
        "                        # Ensure the input to predict is in the correct shape (number of samples, number of features)\n",
        "                        # Xw_normalized should be (number of segments, number of FFT features)\n",
        "                        if Xw_normalized.shape[0] > 0:\n",
        "                            predictions = loaded_model.predict(Xw_normalized)\n",
        "\n",
        "                            st.subheader(\"Resultados del An√°lisis:\")\n",
        "                            # Display predictions for each segment or a summary\n",
        "                            for j, pred_ in enumerate(predictions):\n",
        "                                predicted_label = type_labels[int(pred_-1)] # Adjust index based on your type_labels array\n",
        "                                st.write(f\"Segmento {j+1}: G√©nero estimado - **{predicted_label}**\")\n",
        "\n",
        "                            # Optional: Display a summary prediction (e.g., most frequent prediction)\n",
        "                            from collections import Counter\n",
        "                            if predictions.size > 0:\n",
        "                                most_common_prediction = Counter(predictions).most_common(1)[0][0]\n",
        "                                overall_predicted_label = type_labels[int(most_common_prediction-1)]\n",
        "                                st.subheader(f\"Predicci√≥n General: **{overall_predicted_label}**\")\n",
        "                            else:\n",
        "                                st.warning(\"No se pudieron realizar predicciones para ning√∫n segmento.\")\n",
        "\n",
        "                        else:\n",
        "                            st.error(\"No hay datos procesados para realizar la predicci√≥n.\")\n",
        "                else:\n",
        "                    st.error(\"No se pudo procesar el audio para el an√°lisis FFT.\")\n",
        "\n",
        "            # Clean up the temporary audio file\n",
        "            if audio_path and os.path.exists(audio_path) and \"uploaded_audio.wav\" in audio_path:\n",
        "                 os.remove(audio_path)\n",
        "            elif audio_path and os.path.exists(audio_path) and \"downloaded_audio.wav\" in audio_path:\n",
        "                 os.remove(audio_path)\n",
        "\n",
        "    # Optionally, add a section to display the FFT plot for a segment\n",
        "    # This would require selecting a segment and plotting Xw_normalized[selected_segment]\n",
        "    # against vf. You might need to store Xw_normalized and vf in the session state\n",
        "    # or recompute them if you want to allow plotting after analysis.\n",
        "\n",
        "else:\n",
        "    st.warning(\"El modelo no se carg√≥ correctamente. La predicci√≥n no estar√° disponible.\")"
      ],
      "metadata": {
        "id": "EDXDlpnfreE6",
        "outputId": "99a8f89a-e3d7-482a-a846-3bdb6ed035af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 1_Detector_FFT.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 1_Detector_FFT.py pages/\n"
      ],
      "metadata": {
        "id": "CbqvVCUxRLKO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared\n",
        "\n",
        "#Ejecutar Streamlit\n",
        "!streamlit run 0_Detector.py &>/content/logs.txt & #Cambiar 0_üëã_Hello.py por el nombre de tu archivo principal\n",
        "\n",
        "#Exponer el puerto 8501 con Cloudflare Tunnel\n",
        "!cloudflared tunnel --url http://localhost:8501 > /content/cloudflared.log 2>&1 &\n",
        "\n",
        "#Leer la URL p√∫blica generada por Cloudflare\n",
        "import time\n",
        "time.sleep(5)  # Esperar que se genere la URL\n",
        "\n",
        "import re\n",
        "found_context = False  # Indicador para saber si estamos en la secci√≥n correcta\n",
        "\n",
        "with open('/content/cloudflared.log') as f:\n",
        "    for line in f:\n",
        "        #Detecta el inicio del contexto que nos interesa\n",
        "        if \"Your quick Tunnel has been created\" in line:\n",
        "            found_context = True\n",
        "\n",
        "        #Busca una URL si ya se encontr√≥ el contexto relevante\n",
        "        if found_context:\n",
        "            match = re.search(r'https?://\\S+', line)\n",
        "            if match:\n",
        "                url = match.group(0)  #Extrae la URL encontrada\n",
        "                print(f'Tu aplicaci√≥n est√° disponible en: {url}')\n",
        "                break  #Termina el bucle despu√©s de encontrar la URL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqsYJeXKRSTy",
        "outputId": "c92126e7-4781-4d58-a9a5-b95540b249da"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-05 22:55:50--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.5.0/cloudflared-linux-amd64 [following]\n",
            "--2025-06-05 22:55:51--  https://github.com/cloudflare/cloudflared/releases/download/2025.5.0/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/797840ed-70cb-47b8-a6fe-ecb4b3385c94?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250605%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250605T225551Z&X-Amz-Expires=300&X-Amz-Signature=3484eeadd7f4ebb081122c656a940cca541b1e28cbab71babecefc4f6d9c14d1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-06-05 22:55:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/797840ed-70cb-47b8-a6fe-ecb4b3385c94?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250605%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250605T225551Z&X-Amz-Expires=300&X-Amz-Signature=3484eeadd7f4ebb081122c656a940cca541b1e28cbab71babecefc4f6d9c14d1&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37839075 (36M) [application/octet-stream]\n",
            "Saving to: ‚Äòcloudflared-linux-amd64‚Äô\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  36.09M   141MB/s    in 0.3s    \n",
            "\n",
            "2025-06-05 22:55:51 (141 MB/s) - ‚Äòcloudflared-linux-amd64‚Äô saved [37839075/37839075]\n",
            "\n",
            "Tu aplicaci√≥n est√° disponible en: https://nut-pleased-utilization-stronger.trycloudflare.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "res = input(\"Digite (1) para finalizar la ejecuci√≥n del Dashboard: \")\n",
        "\n",
        "if res.upper() == \"1\":\n",
        "    os.system(\"pkill streamlit\")  # Termina el proceso de Streamlit\n",
        "    print(\"El proceso de Streamlit ha sido finalizado.\")\n"
      ],
      "metadata": {
        "id": "VorqjfObRrnM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}